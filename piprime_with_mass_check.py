#!/usr/bin/env python
"""
PiPrime + HighNineè´¨é‡æ£€æŸ¥çš„æ··åˆç”Ÿæˆå™¨

åŠŸèƒ½:
1. ä½¿ç”¨PiPrime CTC Beam Searchç”Ÿæˆå€™é€‰peptide
2. åŒ…æ‹¬PMC (Precursor Mass Control) ç»“æœ
3. ä½¿ç”¨HighNineçš„precursor massæ£€æŸ¥æ–¹æ³•
4. è¾“å‡º100æ¡é€šè¿‡è´¨é‡æ£€æŸ¥çš„å€™é€‰peptide
"""

import torch
import torch.nn.functional as F
import numpy as np
import logging
from typing import List, Dict, Tuple
from pyteomics import mass as pyteomics_mass
from piprime_mass_calculator import (
    calculate_peptide_mass_piprime,
    calculate_precursor_mass_from_mz,
    check_mass_match,
    normalize_sequence_format,
    AA2MAS,
    H2O_MASS
)

logging.basicConfig(level=logging.INFO, format='%(message)s')
logger = logging.getLogger(__name__)


class PiPrimeWithMassCheck:
    """PiPrimeç”Ÿæˆå™¨ + HighNineè´¨é‡æ£€æŸ¥"""
    
    def __init__(self, model, precursor_mass_tol=50, isotope_error_range=(0, 1), beam_width=500):
        """
        åˆå§‹åŒ–
        
        Parameters:
        -----------
        model : Spec2Pep
            PiPrimeæ¨¡å‹
        precursor_mass_tol : float
            Precursorè´¨é‡å®¹å·® (ppm)
        isotope_error_range : Tuple[int, int]
            åŒä½ç´ è¯¯å·®èŒƒå›´
        beam_width : int
            CTC Beam Searchçš„beamå®½åº¦ï¼ˆé»˜è®¤500ï¼‰
        """
        self.model = model
        self.device = next(model.parameters()).device
        self.precursor_mass_tol = precursor_mass_tol
        self.isotope_error_range = isotope_error_range
        self.beam_width = beam_width
        
        # è·å–decoderå’Œtoken masses
        self.decoder = model.decoder
        self.token_masses = model.decoder._peptide_mass.masses
        
        # ===== é‡è¦ï¼šé‡æ–°åˆå§‹åŒ–CTC decoderï¼Œè®¾ç½®æ›´å¤§çš„beam_width =====
        logger.info(f"ğŸ”§ é‡æ–°åˆå§‹åŒ–CTC Decoder (beam_width={beam_width})")
        
        # å¯¼å…¥CTC decoder - ä½¿ç”¨å½“å‰ç›®å½•
        import sys
        import os
        sys.path.insert(0, os.path.dirname(__file__))
        from PrimeNovo.denovo.ctc_beam_search import CTCBeamSearchDecoder
        
        # åˆ›å»ºæ–°çš„CTC decoderï¼Œä½¿ç”¨æ›´å¤§çš„beam_width
        ctc_params = {"beam": beam_width}
        self.ctc_decoder = CTCBeamSearchDecoder(self.decoder, ctc_params)
        
        logger.info(f"âœ… PiPrimeè´¨é‡æ£€æŸ¥ç”Ÿæˆå™¨åˆå§‹åŒ–å®Œæˆ")
        logger.info(f"   - Beam width: {beam_width}")
        logger.info(f"   - Precursor tolerance: {precursor_mass_tol} ppm")
        logger.info(f"   - Isotope range: {isotope_error_range}")
    
    def generate_candidates_with_mass_check(
        self,
        peaks: torch.Tensor,
        precursor_mz: float,
        precursor_charge: int,
        target_count: int = 100,
        max_candidates: int = 500
    ) -> List[Dict]:
        """
        ç”Ÿæˆå€™é€‰peptideå¹¶è¿›è¡Œè´¨é‡æ£€æŸ¥
        
        Parameters:
        -----------
        peaks : torch.Tensor
            è°±å›¾å³° (n_peaks, 2)
        precursor_mz : float
            Precursor m/z
        precursor_charge : int
            Precursorç”µè·
        target_count : int
            ç›®æ ‡å€™é€‰æ•°é‡ (é»˜è®¤100)
        max_candidates : int
            æœ€å¤§ç”Ÿæˆå€™é€‰æ•° (é»˜è®¤500)
            
        Returns:
        --------
        List[Dict] : é€šè¿‡è´¨é‡æ£€æŸ¥çš„å€™é€‰peptideåˆ—è¡¨
            æ¯ä¸ªdictåŒ…å«: {'peptide': str, 'score': float, 'mass_error_ppm': float, 
                          'source': str, 'passes_mass_check': bool}
        """
        peaks = peaks.to(self.device)
        # ä½¿ç”¨æ­£ç¡®çš„precursorè´¨é‡è®¡ç®—æ–¹æ³•
        precursor_mass = calculate_precursor_mass_from_mz(precursor_mz, precursor_charge)
        precursors = torch.tensor(
            [[precursor_mass, precursor_charge, precursor_mz]],
            dtype=torch.float32,
            device=self.device
        )
        
        results = []
        
        # ===== æ­¥éª¤1: è·å–PMCç»“æœ (è´¨é‡æ§åˆ¶åçš„æœ€ä¼˜ç»“æœ) =====
        logger.info(f"\n{'='*60}")
        logger.info("æ­¥éª¤1: è·å–PMC (Precursor Mass Control) ç»“æœ")
        logger.info(f"{'='*60}")
        
        with torch.no_grad():
            # å‰å‘ä¼ æ’­
            enc_out, enc_mask = self.model.encoder(peaks.unsqueeze(0))
            output_logits, _, _ = self.model.decoder(None, precursors, enc_out, enc_mask)
            log_probs = F.log_softmax(output_logits, dim=-1)
            
            # è·å–PMCç»“æœ (è¿™æ˜¯PiPrimeå†…éƒ¨è´¨é‡æ§åˆ¶åçš„æœ€ä¼˜ç»“æœ)
            # æ³¨æ„: PiPrimeçš„forwardæ–¹æ³•ä¼šè°ƒç”¨PMC
            pmc_peptides, pmc_scores = self.model.forward(
                peaks.unsqueeze(0), 
                precursors, 
                [""]  # dummy true_peps
            )
            
            if pmc_peptides and len(pmc_peptides[0]) > 0:
                pmc_peptide = "".join(pmc_peptides[0])
                pmc_score = pmc_scores[0].item() if torch.is_tensor(pmc_scores[0]) else pmc_scores[0]
                
                # æ£€æŸ¥PMCç»“æœçš„è´¨é‡
                mass_check_result = self._check_precursor_mass(
                    pmc_peptide, precursor_mz, precursor_charge
                )
                
                results.append({
                    'peptide': pmc_peptide,
                    'score': pmc_score,
                    'mass_error_ppm': mass_check_result['mass_error_ppm'],
                    'source': 'PMC',
                    'passes_mass_check': mass_check_result['passes']
                })
                
                logger.info(f"âœ… PMCç»“æœ: {pmc_peptide}")
                logger.info(f"   - Score: {pmc_score:.6f}")
                logger.info(f"   - Mass error: {mass_check_result['mass_error_ppm']:.2f} ppm")
                logger.info(f"   - Passes check: {mass_check_result['passes']}")
        
        # ===== æ­¥éª¤2: ä½¿ç”¨æ”¹è¿›çš„Beam Searchç”Ÿæˆå¤šæ¡å€™é€‰ =====
        logger.info(f"\n{'='*60}")
        logger.info(f"æ­¥éª¤2: Improved Beam Searchç”Ÿæˆå€™é€‰ (target={max_candidates})")
        logger.info(f"{'='*60}")
        
        with torch.no_grad():
            # å°†log_probsè½¬æ¢ä¸ºå½’ä¸€åŒ–çš„æ¦‚ç‡çŸ©é˜µï¼ˆæœ€å¤§å€¼ç¼©æ”¾åˆ°20ï¼‰
            probs = F.softmax(output_logits[0], dim=-1)  # [seq_len, vocab_size]
            
            # ç¼©æ”¾åˆ°æœ€å¤§å€¼20
            max_prob = probs.max()
            if max_prob > 0:
                prob_matrix = probs * (20.0 / max_prob)
            else:
                prob_matrix = probs * 20.0
            
            logger.info(f"  Probability matrix shape: {prob_matrix.shape}")
            logger.info(f"  Max value: {prob_matrix.max().item():.4f}")
            logger.info(f"  Min value: {prob_matrix.min().item():.4f}")
            
            # ä½¿ç”¨æ”¹è¿›çš„Beam Search
            beam_candidates = self._simple_beam_search(
                prob_matrix,  # å½’ä¸€åŒ–ä¸”ç¼©æ”¾åˆ°20çš„æ¦‚ç‡çŸ©é˜µ
                precursor_mz=precursor_mz,
                precursor_charge=precursor_charge,
                beam_width=100,
                top_n=10,
                max_length=30
            )
            
            logger.info(f"âœ… Beam Searchè¿”å›äº† {len(beam_candidates)} æ¡å€™é€‰")
            
            # æ˜¾ç¤ºå‰5æ¡
            for idx, cand in enumerate(beam_candidates[:5]):
                logger.info(f"  Beam #{idx+1}: {cand['peptide']} (score={cand['score']:.4f}, len={len(cand['peptide'])})")
            
            for cand in beam_candidates:
                peptide = cand['peptide']
                score = cand['score']
                
                if peptide and peptide not in [r['peptide'] for r in results]:
                    # æ£€æŸ¥è´¨é‡
                    mass_check_result = self._check_precursor_mass(
                        peptide, precursor_mz, precursor_charge
                    )
                    
                    results.append({
                        'peptide': peptide,
                        'score': score,
                        'mass_error_ppm': mass_check_result['mass_error_ppm'],
                        'source': 'Simple_BeamSearch',
                        'passes_mass_check': mass_check_result['passes']
                    })
        
        logger.info(f"âœ… ç”Ÿæˆäº† {len(results)} æ¡å€™é€‰peptide")
        
        # ===== æ­¥éª¤3: è¿‡æ»¤å’Œæ’åº =====
        logger.info(f"\n{'='*60}")
        logger.info("æ­¥éª¤3: è´¨é‡æ£€æŸ¥å’Œæ’åº")
        logger.info(f"{'='*60}")
        
        # ç»Ÿè®¡
        passed = [r for r in results if r['passes_mass_check']]
        failed = [r for r in results if not r['passes_mass_check']]
        
        logger.info(f"é€šè¿‡è´¨é‡æ£€æŸ¥: {len(passed)}/{len(results)}")
        logger.info(f"æœªé€šè¿‡è´¨é‡æ£€æŸ¥: {len(failed)}/{len(results)}")
        
        # ä¼˜å…ˆè¿”å›é€šè¿‡è´¨é‡æ£€æŸ¥çš„ï¼Œç„¶åæ˜¯æœªé€šè¿‡çš„
        # æŒ‰scoreæ’åº
        passed_sorted = sorted(passed, key=lambda x: x['score'], reverse=True)
        failed_sorted = sorted(failed, key=lambda x: x['score'], reverse=True)
        
        # åˆå¹¶ï¼šå…ˆé€šè¿‡çš„ï¼Œå†æœªé€šè¿‡çš„
        final_results = passed_sorted + failed_sorted
        
        # é™åˆ¶åˆ°target_count
        final_results = final_results[:target_count]
        
        logger.info(f"\nâœ… æœ€ç»ˆè¿”å› {len(final_results)} æ¡å€™é€‰peptide")
        logger.info(f"   - é€šè¿‡è´¨é‡æ£€æŸ¥: {sum(1 for r in final_results if r['passes_mass_check'])}")
        logger.info(f"   - æœªé€šè¿‡è´¨é‡æ£€æŸ¥: {sum(1 for r in final_results if not r['passes_mass_check'])}")
        
        return final_results
    
    def _ctc_collapse(self, tokens: List[int]) -> List[int]:
        """
        CTCè§„çº¦ï¼šå»é™¤é‡å¤çš„token
        ä¾‹å¦‚: [1, 1, 2, 2, 3] -> [1, 2, 3]
        """
        if not tokens:
            return []
        
        collapsed = [tokens[0]]
        for t in tokens[1:]:
            if t != collapsed[-1]:
                collapsed.append(t)
        return collapsed
    
    def _calculate_peptide_mass(self, tokens: List[int]) -> float:
        """
        ä½¿ç”¨PiPrimeçš„æ–¹å¼è®¡ç®—peptideè´¨é‡
        
        Parameters:
        -----------
        tokens : List[int]
            Tokenåºåˆ—
            
        Returns:
        --------
        float : è´¨é‡ï¼ˆDaï¼‰ï¼Œå«æ°´
        """
        # å°†tokensè½¬æ¢ä¸ºåºåˆ—å­—ç¬¦ä¸²
        sequence = ''.join([self.decoder._idx2aa.get(t, '') for t in tokens
                           if t != self.decoder.get_blank_idx() and t != self.decoder.get_pad_idx()])
        
        # ä½¿ç”¨PiPrimeçš„è´¨é‡è®¡ç®—æ–¹æ³•
        peptide_mass = calculate_peptide_mass_piprime(sequence, add_water=True)
        return peptide_mass
    
    def _simple_beam_search(self, prob_matrix: torch.Tensor, precursor_mz: float,
                           precursor_charge: int, beam_width: int = 100,
                           top_n: int = 10, max_length: int = 30) -> List[Dict]:
        """
        æ”¹è¿›çš„Beam Searchï¼ˆå€Ÿé‰´multi_path_dpï¼‰
        - è¾“å…¥ï¼šå½’ä¸€åŒ–ä¸”æœ€å¤§å€¼ç¼©æ”¾åˆ°20çš„æ­£æ•°æ¦‚ç‡çŸ©é˜µ
        - æ¯æ­¥åªè€ƒè™‘Top-Nä¸ªæ°¨åŸºé…¸
        - ä¸åœ¨æœç´¢è¿‡ç¨‹ä¸­è¿›è¡Œè´¨é‡è¿‡æ»¤ï¼Œåªåœ¨æœ€åè¿‡æ»¤
        
        Parameters:
        -----------
        prob_matrix : torch.Tensor
            æ¦‚ç‡çŸ©é˜µ [seq_len, vocab_size]ï¼Œå·²å½’ä¸€åŒ–ä¸”ç¼©æ”¾åˆ°20
        precursor_mz : float
            Precursor m/z
        precursor_charge : int
            Precursorç”µè·
        beam_width : int
            Beamå®½åº¦ï¼ˆç”Ÿæˆçš„peptideæ•°é‡ï¼‰
        top_n : int
            æ¯æ­¥è€ƒè™‘çš„Top-Næ°¨åŸºé…¸
        max_length : int
            æœ€å¤§åºåˆ—é•¿åº¦
            
        Returns:
        --------
        List[Dict] : å€™é€‰åˆ—è¡¨ï¼Œæ¯ä¸ªåŒ…å« {'peptide': str, 'score': float}
        """
        seq_len, vocab_size = prob_matrix.shape
        
        # è®¡ç®—precursor masså’Œè´¨é‡èŒƒå›´ï¼ˆç”¨äºæœ€ç»ˆè¿‡æ»¤ï¼‰
        precursor_mass = calculate_precursor_mass_from_mz(precursor_mz, precursor_charge)
        mass_tolerance_da = 0.5  # æ”¾å®½åˆ°Â±0.5 Da
        # æ³¨æ„ï¼šprecursor_massæ˜¯å«æ°´çš„ï¼Œpeptide_massä¹Ÿæ˜¯å«æ°´çš„ï¼Œæ‰€ä»¥ç›´æ¥æ¯”è¾ƒ
        min_mass = precursor_mass - mass_tolerance_da
        max_mass = precursor_mass + mass_tolerance_da
        
        logger.info(f"  Precursor mass: {precursor_mass:.4f} Da")
        logger.info(f"  Mass range: [{min_mass:.4f}, {max_mass:.4f}] Da (Â±{mass_tolerance_da} Da)")
        logger.info(f"  Beam width: {beam_width}, Top-N: {top_n}")
        
        # åˆå§‹åŒ–ï¼šä¸€ä¸ªç©ºè·¯å¾„
        paths = [(0.0, [])]  # (ç´¯ç§¯æ¦‚ç‡, tokenåºåˆ—)
        
        # é€æ­¥æ‰©å±•
        for t in range(min(seq_len, max_length)):
            # è·å–å½“å‰ä½ç½®æ¦‚ç‡æœ€é«˜çš„Top-Nä¸ªæ°¨åŸºé…¸
            top_probs, top_indices = torch.topk(prob_matrix[t], top_n)
            
            new_paths = []
            
            # å¯¹æ¯ä¸ªç°æœ‰è·¯å¾„
            for current_prob, current_path in paths:
                # å°è¯•æ·»åŠ æ¯ä¸ªTop-Næ°¨åŸºé…¸
                for prob, idx in zip(top_probs, top_indices):
                    idx = idx.item()
                    prob = prob.item()
                    
                    # è·³è¿‡blank token (0)
                    if idx == 0:
                        continue
                    
                    # è·å–æ°¨åŸºé…¸
                    aa = self.decoder._idx2aa.get(idx, '')
                    if not aa:
                        continue
                    
                    # CTCå»é‡ï¼šå¦‚æœä¸å‰ä¸€ä¸ªtokenç›¸åŒï¼Œè·³è¿‡
                    if current_path and idx == current_path[-1]:
                        continue
                    
                    # åˆ›å»ºæ–°è·¯å¾„
                    new_path = current_path + [idx]
                    new_prob = current_prob + prob  # ç›´æ¥ç´¯åŠ æ¦‚ç‡ï¼ˆå·²ç»æ˜¯æ­£æ•°ï¼‰
                    
                    # ä¸è¿›è¡Œè´¨é‡è¿‡æ»¤ï¼Œç›´æ¥æ·»åŠ 
                    new_paths.append((new_prob, new_path))
            
            # ä¿ç•™Top-Kè·¯å¾„
            new_paths.sort(reverse=True)  # æŒ‰æ¦‚ç‡é™åº
            paths = new_paths[:beam_width]
            
            if not paths:
                logger.warning(f"  æ‰€æœ‰è·¯å¾„åœ¨æ­¥éª¤{t}è¢«å‰ªæ")
                break
            
            # æ¯5æ­¥è¾“å‡ºçŠ¶æ€
            if t % 5 == 0:
                logger.info(f"  Step {t}: created {len(new_paths)} new paths, kept {len(paths)} paths")
                if len(paths) > 0:
                    # æ˜¾ç¤ºç¬¬ä¸€æ¡è·¯å¾„çš„ä¿¡æ¯
                    first_path = paths[0]
                    collapsed = self._ctc_collapse(first_path[1])
                    mass = self._calculate_peptide_mass(collapsed)
                    logger.info(f"    Top path: prob={first_path[0]:.2f}, len={len(collapsed)}, mass={mass:.2f}")
        
        logger.info(f"  Beam searchå®Œæˆ: {len(paths)} æ¡è·¯å¾„")
        
        # æœ€ç»ˆè´¨é‡è¿‡æ»¤å¹¶è½¬æ¢ä¸ºpeptide
        candidates = []
        filtered_out = 0
        too_short = 0
        
        for prob, tokens in paths:
            # CTCè§„çº¦
            collapsed = self._ctc_collapse(tokens)
            
            # è®¡ç®—è´¨é‡
            peptide_mass = self._calculate_peptide_mass(collapsed)
            
            # ä¸¥æ ¼çš„è´¨é‡è¿‡æ»¤
            if not (min_mass <= peptide_mass <= max_mass):
                filtered_out += 1
                continue
            
            # è½¬æ¢ä¸ºæ°¨åŸºé…¸åºåˆ—
            aa_seq = [self.decoder._idx2aa.get(t, '') for t in collapsed]
            
            # åè½¬ï¼ˆå¦‚æœéœ€è¦ï¼‰
            if self.decoder.reverse:
                aa_seq = list(reversed(aa_seq))
            
            peptide = "".join(aa_seq)
            
            # è¿‡æ»¤å¤ªçŸ­çš„åºåˆ—
            if len(peptide) >= 5:
                candidates.append({
                    'peptide': peptide,
                    'score': prob,  # ä½¿ç”¨ç´¯ç§¯æ¦‚ç‡ä½œä¸ºåˆ†æ•°
                    'mass': peptide_mass
                })
            else:
                too_short += 1
        
        logger.info(f"  è´¨é‡è¿‡æ»¤ç»Ÿè®¡:")
        logger.info(f"    - æ€»è·¯å¾„: {len(paths)}")
        logger.info(f"    - è´¨é‡ä¸åŒ¹é…: {filtered_out}")
        logger.info(f"    - åºåˆ—å¤ªçŸ­: {too_short}")
        logger.info(f"    - æœ€ç»ˆå€™é€‰: {len(candidates)}")
        
        return candidates
    
    def _greedy_decode_topk_old(self, log_probs: torch.Tensor, precursor_mz: float,
                           precursor_charge: int, topk: int = 100) -> List[Dict]:
        """
        ä½¿ç”¨æ”¹è¿›çš„Greedy Decodingç”ŸæˆTop-Kå€™é€‰peptide
        
        æ”¹è¿›ç­–ç•¥ï¼š
        1. ä½¿ç”¨Beam Searchå˜ä½“ï¼Œåœ¨æ¯æ­¥ä¿ç•™å¤šæ¡è·¯å¾„
        2. **æ¯æ­¥è¿›è¡ŒCTCè§„çº¦å¹¶æ£€æŸ¥precursor mass**
        3. å‰ªæè¶…è¿‡precursor massçš„è·¯å¾„
        4. ç¡®ä¿ç”Ÿæˆè´¨é‡åŒ¹é…çš„peptideåºåˆ—
        
        Parameters:
        -----------
        log_probs : torch.Tensor
            Logæ¦‚ç‡çŸ©é˜µ [seq_len, vocab_size]
        precursor_mz : float
            Precursor m/z
        precursor_charge : int
            Precursorç”µè·
        topk : int
            ç›®æ ‡å€™é€‰æ•°é‡
            
        Returns:
        --------
        List[Dict] : å€™é€‰åˆ—è¡¨ï¼Œæ¯ä¸ªåŒ…å« {'tokens': List[int], 'score': float}
        """
        seq_len, vocab_size = log_probs.shape
        probs = torch.exp(log_probs)
        
        # è®¡ç®—precursor masså’Œè´¨é‡ä¸Šé™
        precursor_mass = calculate_precursor_mass_from_mz(precursor_mz, precursor_charge)
        
        # ä½¿ç”¨0.1 Daçš„ä¸¥æ ¼è´¨é‡æ§åˆ¶
        mass_tolerance_da = 0.1
        min_mass = precursor_mass - mass_tolerance_da  # ä¸‹é™
        max_mass = precursor_mass + mass_tolerance_da  # ä¸Šé™
        
        # è®¡ç®—é¢„æœŸçš„peptideé•¿åº¦ï¼ˆåŸºäºå¹³å‡æ°¨åŸºé…¸è´¨é‡çº¦110 Daï¼‰
        expected_length = int(precursor_mass / 110)
        min_length_for_pruning = max(8, expected_length - 3)  # è‡³å°‘8ä¸ªAAï¼Œæˆ–é¢„æœŸé•¿åº¦-3
        
        logger.info(f"  Precursor mass: {precursor_mass:.4f} Da")
        logger.info(f"  Mass range: [{min_mass:.4f}, {max_mass:.4f}] Da (Â±{mass_tolerance_da} Da)")
        logger.info(f"  Expected peptide length: ~{expected_length} AA")
        logger.info(f"  Will start pruning after {min_length_for_pruning} AA")
        
        # ä½¿ç”¨åŠ¨æ€beam widthç­–ç•¥
        # ç¬¬1æ­¥ï¼š10ä¸ªbeamï¼Œç¬¬2æ­¥ï¼š100ä¸ªbeamï¼Œç¬¬3æ­¥åŠä¹‹åï¼š1000ä¸ªbeam
        beams = [{'tokens': [], 'score': 0.0, 'mass': 0.0}]
        
        pruned_count = 0  # ç»Ÿè®¡è¢«å‰ªæçš„æ•°é‡
        
        for t in range(seq_len):
            # åŠ¨æ€è°ƒæ•´beam width
            if t == 0:
                beam_width = 10
            elif t == 1:
                beam_width = 100
            else:
                beam_width = 1000
            
            new_beams = []
            step_pruned = 0  # æœ¬æ­¥è¢«å‰ªæçš„æ•°é‡
            step_processed = 0  # æœ¬æ­¥å¤„ç†çš„tokenæ•°
            
            for beam in beams:
                # è·å–å½“å‰æ—¶é—´æ­¥çš„Top-Kæ¦‚ç‡
                top_k = min(10, vocab_size)  # æ¯æ­¥é€‰æ‹©Top-10
                top_probs, top_indices = torch.topk(probs[t], top_k)
                
                for prob, idx in zip(top_probs, top_indices):
                    step_processed += 1
                    idx = idx.item()
                    
                    # è·³è¿‡ç‰¹æ®Štokenï¼ˆblankå’ŒEOSï¼‰
                    if idx == 0 or idx == 27:
                        continue
                    
                    # è·å–æ°¨åŸºé…¸/ä¿®é¥°
                    aa = self.decoder._idx2aa.get(idx, '')
                    if not aa:
                        continue
                    
                    # ===== æ”¯æŒä¿®é¥°ï¼šä¸å†è·³è¿‡ä¿®é¥°token =====
                    # ä¿®é¥°æ ‡è®°ï¼ˆå¦‚+42.011, -17.027ï¼‰å’Œå¸¦ä¿®é¥°çš„æ°¨åŸºé…¸ï¼ˆå¦‚M+15.995ï¼‰éƒ½ä¿ç•™
                    
                    # CTCå»é‡ï¼šå¦‚æœä¸å‰ä¸€ä¸ªtokenç›¸åŒï¼Œè·³è¿‡
                    if beam['tokens'] and idx == beam['tokens'][-1]:
                        continue
                    
                    # åˆ›å»ºæ–°tokenåºåˆ—
                    new_tokens = beam['tokens'] + [idx]
                    
                    # ===== å…³é”®ï¼šCTCè§„çº¦å¹¶è®¡ç®—è´¨é‡ï¼ˆæ”¯æŒä¿®é¥°ï¼‰=====
                    collapsed_tokens = self._ctc_collapse(new_tokens)
                    current_mass = self._calculate_peptide_mass(collapsed_tokens)
                    
                    # è°ƒè¯•ï¼šåœ¨ç¬¬ä¸€æ­¥è¾“å‡ºè´¨é‡è®¡ç®—è¯¦æƒ…
                    if t == 0 and len(new_beams) < 3:
                        aa_seq = [self.decoder._idx2aa.get(tok, '?') for tok in collapsed_tokens]
                        logger.info(f"    Debug t={t}: tokens={collapsed_tokens[:5]}..., aa={''.join(aa_seq)}, mass={current_mass:.4f}, range=[{min_mass:.4f}, {max_mass:.4f}]")
                    
                    # ===== æ™ºèƒ½å‰ªæç­–ç•¥ =====
                    # 1. ç»Ÿè®¡æ°¨åŸºé…¸æ•°é‡ï¼ˆä¸åŒ…æ‹¬ä¿®é¥°æ ‡è®°ï¼‰
                    aa_count = sum(1 for tok in collapsed_tokens
                                  if not (self.decoder._idx2aa.get(tok, '').startswith(('+', '-'))))
                    
                    # 2. åªåœ¨åºåˆ—é•¿åº¦è¶³å¤Ÿæ—¶æ‰è¿›è¡Œè´¨é‡å‰ªæ
                    if aa_count >= min_length_for_pruning:
                        # ä¸¥æ ¼çš„è´¨é‡æ§åˆ¶ï¼šå¿…é¡»åœ¨[min_mass, max_mass]èŒƒå›´å†…
                        if current_mass < min_mass or current_mass > max_mass:
                            step_pruned += 1
                            continue
                    else:
                        # åºåˆ—è¿˜å¤ªçŸ­ï¼Œåªå‰ªææ˜æ˜¾è¿‡å¤§çš„ï¼ˆè¶…è¿‡2å€precursor massï¼‰
                        if current_mass > precursor_mass * 2:
                            step_pruned += 1
                            continue
                    
                    # åˆ›å»ºæ–°beam
                    new_beam = {
                        'tokens': new_tokens,
                        'score': beam['score'] + torch.log(prob).item(),
                        'mass': current_mass
                    }
                    new_beams.append(new_beam)
            
            pruned_count += step_pruned
            
            # ä¿ç•™Top-K beams
            new_beams.sort(key=lambda x: x['score'], reverse=True)
            beams = new_beams[:beam_width]
            
            # æ¯10æ­¥è¾“å‡ºä¸€æ¬¡çŠ¶æ€
            if t % 10 == 0 and t > 0:
                logger.info(f"  Step {t}/{seq_len}: {len(beams)} beams, processed {step_processed}, pruned {step_pruned}")
            
            # å‰å‡ æ­¥è¾“å‡ºè¯¦ç»†ä¿¡æ¯
            if t <= 2:
                logger.info(f"  Step {t}: beam_width={beam_width}, processed {step_processed} tokens, created {len(new_beams)} beams, kept {len(beams)}, pruned {step_pruned}")
            
            # å¦‚æœæ‰€æœ‰beaméƒ½è¢«å‰ªæäº†ï¼Œæå‰ç»“æŸ
            if not beams:
                logger.warning(f"  All beams pruned at step {t}! Total pruned: {pruned_count}")
                break
        
        logger.info(f"  Beam search completed: {len(beams)} final beams, total pruned: {pruned_count}")
        
        # è¿‡æ»¤å’Œå»é‡ï¼ˆæ”¯æŒä¿®é¥°ï¼‰
        candidates = []
        seen_sequences = set()
        
        for beam in beams:
            tokens = beam['tokens']
            
            # è¿‡æ»¤æ¡ä»¶ï¼šé•¿åº¦è‡³å°‘8ä¸ªtokenï¼ˆå¯èƒ½åŒ…å«ä¿®é¥°tokenï¼‰
            if len(tokens) < 8:
                continue
            
            # æ£€æŸ¥æ˜¯å¦åŒ…å«æœ‰æ•ˆçš„æ°¨åŸºé…¸ï¼ˆè‡³å°‘è¦æœ‰ä¸€äº›æ°¨åŸºé…¸ï¼‰
            aa_count = 0
            valid = True
            for t in tokens:
                aa = self.decoder._idx2aa.get(t, '')
                if not aa:
                    valid = False
                    break
                # ç»Ÿè®¡æ°¨åŸºé…¸æ•°é‡ï¼ˆä¸åŒ…æ‹¬çº¯ä¿®é¥°æ ‡è®°ï¼‰
                if not (aa.startswith('+') or aa.startswith('-')):
                    aa_count += 1
            
            # è‡³å°‘è¦æœ‰5ä¸ªæ°¨åŸºé…¸
            if not valid or aa_count < 5:
                continue
            
            # å»é‡
            token_tuple = tuple(tokens)
            if token_tuple not in seen_sequences:
                seen_sequences.add(token_tuple)
                candidates.append({
                    'tokens': tokens,
                    'score': np.exp(beam['score'])
                })
        
        # å¦‚æœå€™é€‰ä¸å¤Ÿï¼Œé™ä½é•¿åº¦è¦æ±‚
        if len(candidates) < topk:
            for beam in beams:
                tokens = beam['tokens']
                
                # é™ä½åˆ°è‡³å°‘5ä¸ªtoken
                if len(tokens) < 5:
                    continue
                
                # æ£€æŸ¥æœ‰æ•ˆæ€§
                aa_count = 0
                valid = True
                for t in tokens:
                    aa = self.decoder._idx2aa.get(t, '')
                    if not aa:
                        valid = False
                        break
                    if not (aa.startswith('+') or aa.startswith('-')):
                        aa_count += 1
                
                # è‡³å°‘è¦æœ‰3ä¸ªæ°¨åŸºé…¸
                if not valid or aa_count < 3:
                    continue
                
                token_tuple = tuple(tokens)
                if token_tuple not in seen_sequences:
                    seen_sequences.add(token_tuple)
                    candidates.append({
                        'tokens': tokens,
                        'score': np.exp(beam['score'])
                    })
                    
                    if len(candidates) >= topk:
                        break
        
        # æŒ‰åˆ†æ•°æ’åº
        candidates.sort(key=lambda x: x['score'], reverse=True)
        
        return candidates[:topk]
    
    def _check_precursor_mass(
        self,
        peptide: str,
        precursor_mz: float,
        precursor_charge: int
    ) -> Dict:
        """
        æ£€æŸ¥peptideçš„precursor massæ˜¯å¦åŒ¹é…
        ä½¿ç”¨pyteomicsè®¡ç®—è´¨é‡ï¼Œä½†æ­£ç¡®å¤„ç†PiPrimeçš„ä¿®é¥°æ ¼å¼
        
        Returns:
        --------
        Dict : {'passes': bool, 'mass_error_ppm': float, 'best_isotope': int}
        """
        try:
            # å°†PiPrimeæ ¼å¼è½¬æ¢ä¸ºpyteomicsæ ¼å¼
            # PiPrime: C+57.021 -> pyteomics: C[+57.021]
            pyteomics_peptide = self._convert_to_pyteomics_format(peptide)
            
            # ä½¿ç”¨pyteomicsè®¡ç®—è´¨é‡
            peptide_mass = pyteomics_mass.calculate_mass(
                sequence=pyteomics_peptide,
                charge=0  # ä¸­æ€§è´¨é‡
            )
            
            # è®¡ç®—ç†è®ºm/z
            proton_mass = 1.007276
            calc_mz = (peptide_mass + precursor_charge * proton_mass) / precursor_charge
            
            # æ£€æŸ¥æ‰€æœ‰åŒä½ç´ è¯¯å·®
            best_error = float('inf')
            best_isotope = 0
            
            for isotope in range(
                self.isotope_error_range[0],
                self.isotope_error_range[1] + 1
            ):
                # è€ƒè™‘åŒä½ç´ è¯¯å·®
                corrected_mz = precursor_mz - isotope * 1.00335 / precursor_charge
                
                # è®¡ç®—PPMè¯¯å·®
                mass_error_ppm = (calc_mz - corrected_mz) / corrected_mz * 1e6
                
                if abs(mass_error_ppm) < abs(best_error):
                    best_error = mass_error_ppm
                    best_isotope = isotope
            
            # åˆ¤æ–­æ˜¯å¦é€šè¿‡
            passes = abs(best_error) < self.precursor_mass_tol
            
            return {
                'passes': passes,
                'mass_error_ppm': best_error,
                'best_isotope': best_isotope
            }
            
        except Exception as e:
            logger.warning(f"è´¨é‡æ£€æŸ¥å¤±è´¥ for {peptide}: {e}")
            return {
                'passes': False,
                'mass_error_ppm': float('inf'),
                'best_isotope': 0
            }
    
    def _convert_to_pyteomics_format(self, peptide: str) -> str:
        """
        å°†PiPrimeçš„ä¿®é¥°æ ¼å¼è½¬æ¢ä¸ºpyteomicsæ ¼å¼
        
        æ”¯æŒçš„è¾“å…¥æ ¼å¼:
        - PiPrimeæ ¼å¼: C+57.021, M+15.995, N+0.984
        - MGFæ‹¬å·æ ¼å¼: C(+57.02), M(+15.99), N(+.98)
        
        è¾“å‡ºæ ¼å¼:
        - Pyteomicsæ ¼å¼: C[+57.021], M[+15.995], N[+0.984]
        
        æ³¨æ„ï¼šPiPrimeä¸­C+57.021æ˜¯æ•´ä½“tokenï¼Œè´¨é‡å·²ç»åŒ…å«äº†Cå’Œä¿®é¥°
        ä½†pyteomicséœ€è¦åˆ†å¼€å¤„ç†ï¼Œæ‰€ä»¥æˆ‘ä»¬éœ€è¦ï¼š
        1. è¯†åˆ«ä¿®é¥°çš„æ°¨åŸºé…¸ï¼ˆå¦‚C+57.021æˆ–C(+57.02)ï¼‰
        2. è½¬æ¢ä¸ºpyteomicsæ ¼å¼ï¼ˆC[+57.021]ï¼‰
        3. pyteomicsä¼šè‡ªåŠ¨å¤„ç†ï¼šCçš„è´¨é‡ + ä¿®é¥°è´¨é‡
        """
        import re
        from piprime_mass_calculator import normalize_sequence_format
        
        # é¦–å…ˆæ ‡å‡†åŒ–æ ¼å¼ï¼šå°†MGFæ ¼å¼è½¬æ¢ä¸ºPiPrimeæ ¼å¼
        peptide = normalize_sequence_format(peptide)
        
        # åŒ¹é…ä¿®é¥°çš„æ°¨åŸºé…¸ï¼šå­—æ¯åè·Ÿ+æˆ–-å’Œæ•°å­—
        # ä¾‹å¦‚ï¼šC+57.021, M+15.995, N+0.984, Q+0.984
        pattern = r'([A-Z])([\+\-][\d\.]+)'
        
        def replace_mod(match):
            aa = match.group(1)
            mod = match.group(2)
            return f"{aa}[{mod}]"
        
        pyteomics_peptide = re.sub(pattern, replace_mod, peptide)
        
        # æ›¿æ¢Iä¸ºLï¼ˆpyteomicsä¸­å®ƒä»¬è´¨é‡ç›¸åŒï¼‰
        pyteomics_peptide = pyteomics_peptide.replace('I', 'L')
        
        return pyteomics_peptide
    
    def _clean_peptide_sequence(self, peptide: str) -> str:
        """æ¸…ç†peptideåºåˆ—ï¼Œå»é™¤ä¿®é¥°æ ‡è®°"""
        import re
        # å»é™¤ä¿®é¥°æ ‡è®° (å¦‚ M+15.995, N+0.984ç­‰)
        clean = re.sub(r'\+[\d\.]+', '', peptide)
        clean = re.sub(r'\-[\d\.]+', '', peptide)
        # æ›¿æ¢Lä¸ºI (è´¨é‡ç›¸åŒ)
        clean = clean.replace('L', 'I')
        return clean


def test_piprime_with_mass_check():
    """æµ‹è¯•å‡½æ•°"""
    import sys
    import os
    
    # æ·»åŠ è·¯å¾„
    piprime_path = os.path.join(os.path.dirname(__file__), '..', 'pi-PrimeNovo')
    sys.path.insert(0, piprime_path)
    
    from PrimeNovo.denovo.model import Spec2Pep
    from pyteomics import mgf
    
    # åŠ è½½æ¨¡å‹
    model_path = os.path.join(piprime_path, "model_massive.ckpt")
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    
    logger.info(f"åŠ è½½PiPrimeæ¨¡å‹: {model_path}")
    model = Spec2Pep.load_from_checkpoint(model_path, map_location=device)
    model.eval()
    model.to(device)
    
    # åˆ›å»ºç”Ÿæˆå™¨
    generator = PiPrimeWithMassCheck(
        model, 
        precursor_mass_tol=50, 
        isotope_error_range=(0, 1)
    )
    
    # åŠ è½½æµ‹è¯•è°±å›¾
    mgf_file = os.path.join(piprime_path, "testdata", "high_nine_validation_1000_converted.mgf")
    
    with mgf.MGF(mgf_file) as reader:
        for idx, spec in enumerate(reader):
            if idx >= 1:  # åªæµ‹è¯•ç¬¬ä¸€ä¸ª
                break
            
            # æå–ä¿¡æ¯
            mz_array = spec['m/z array']
            intensity_array = spec['intensity array']
            
            pepmass = spec['params'].get('pepmass', [0])
            precursor_mz = pepmass[0] if isinstance(pepmass, (list, tuple)) else pepmass
            
            charge = spec['params'].get('charge', [2])
            precursor_charge = charge[0] if isinstance(charge, (list, tuple)) else charge
            if isinstance(precursor_charge, str):
                precursor_charge = int(precursor_charge.replace('+', ''))
            
            # é¢„å¤„ç†è°±å›¾
            from piprime_reranker import process_peaks, load_piprime_config
            config = load_piprime_config()
            peaks = process_peaks(
                mz_array, intensity_array, 
                precursor_mz, precursor_charge, 
                config
            )
            
            # ç”Ÿæˆå€™é€‰
            logger.info(f"\n{'='*80}")
            logger.info(f"æµ‹è¯•è°±å›¾ #{idx}")
            logger.info(f"{'='*80}")
            logger.info(f"Precursor m/z: {precursor_mz:.4f}")
            logger.info(f"Charge: {precursor_charge}")
            logger.info(f"Peaks: {len(mz_array)}")
            
            candidates = generator.generate_candidates_with_mass_check(
                peaks, 
                precursor_mz, 
                precursor_charge,
                target_count=100,
                max_candidates=500
            )
            
            # æ˜¾ç¤ºç»“æœ
            logger.info(f"\n{'='*80}")
            logger.info("Top 10 å€™é€‰peptide:")
            logger.info(f"{'='*80}")
            logger.info(f"{'Rank':<6}{'Peptide':<25}{'Score':<12}{'Mass Error':<15}{'Pass':<8}{'Source'}")
            logger.info(f"{'-'*80}")
            
            for i, cand in enumerate(candidates[:10], 1):
                pass_mark = "âœ…" if cand['passes_mass_check'] else "âŒ"
                logger.info(
                    f"{i:<6}{cand['peptide']:<25}{cand['score']:<12.6f}"
                    f"{cand['mass_error_ppm']:<15.2f}{pass_mark:<8}{cand['source']}"
                )
            
            # ç»Ÿè®¡
            logger.info(f"\n{'='*80}")
            logger.info("ç»Ÿè®¡ä¿¡æ¯:")
            logger.info(f"{'='*80}")
            logger.info(f"æ€»å€™é€‰æ•°: {len(candidates)}")
            logger.info(f"é€šè¿‡è´¨é‡æ£€æŸ¥: {sum(1 for c in candidates if c['passes_mass_check'])}")
            logger.info(f"PMCç»“æœ: {sum(1 for c in candidates if c['source'] == 'PMC')}")
            logger.info(f"CTC Beam Search: {sum(1 for c in candidates if c['source'] == 'CTC_BeamSearch')}")
            
            break


if __name__ == "__main__":
    test_piprime_with_mass_check()